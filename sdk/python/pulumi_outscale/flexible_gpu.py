# coding=utf-8
# *** WARNING: this file was generated by pulumi-language-python. ***
# *** Do not edit by hand unless you're certain you know what you are doing! ***

import builtins as _builtins
import warnings
import sys
import pulumi
import pulumi.runtime
from typing import Any, Mapping, Optional, Sequence, Union, overload
if sys.version_info >= (3, 11):
    from typing import NotRequired, TypedDict, TypeAlias
else:
    from typing_extensions import NotRequired, TypedDict, TypeAlias
from . import _utilities
from . import outputs
from ._inputs import *

__all__ = ['FlexibleGpuArgs', 'FlexibleGpu']

@pulumi.input_type
class FlexibleGpuArgs:
    def __init__(__self__, *,
                 model_name: pulumi.Input[_builtins.str],
                 subregion_name: pulumi.Input[_builtins.str],
                 delete_on_vm_deletion: Optional[pulumi.Input[_builtins.bool]] = None,
                 generation: Optional[pulumi.Input[_builtins.str]] = None,
                 timeouts: Optional[pulumi.Input['FlexibleGpuTimeoutsArgs']] = None):
        """
        The set of arguments for constructing a FlexibleGpu resource.
        :param pulumi.Input[_builtins.str] model_name: The model of fGPU you want to allocate. For more information, see [About Flexible GPUs](https://docs.outscale.com/en/userguide/About-Flexible-GPUs.html).
        :param pulumi.Input[_builtins.str] subregion_name: The Subregion in which you want to create the fGPU.
        :param pulumi.Input[_builtins.bool] delete_on_vm_deletion: If true, the fGPU is deleted when the VM is terminated.
        :param pulumi.Input[_builtins.str] generation: The processor generation that the fGPU must be compatible with. If not specified, the oldest possible processor generation is selected (as provided by [ReadFlexibleGpuCatalog](https://docs.outscale.com/api#readflexiblegpucatalog) for the specified model of fGPU).
        """
        pulumi.set(__self__, "model_name", model_name)
        pulumi.set(__self__, "subregion_name", subregion_name)
        if delete_on_vm_deletion is not None:
            pulumi.set(__self__, "delete_on_vm_deletion", delete_on_vm_deletion)
        if generation is not None:
            pulumi.set(__self__, "generation", generation)
        if timeouts is not None:
            pulumi.set(__self__, "timeouts", timeouts)

    @_builtins.property
    @pulumi.getter(name="modelName")
    def model_name(self) -> pulumi.Input[_builtins.str]:
        """
        The model of fGPU you want to allocate. For more information, see [About Flexible GPUs](https://docs.outscale.com/en/userguide/About-Flexible-GPUs.html).
        """
        return pulumi.get(self, "model_name")

    @model_name.setter
    def model_name(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "model_name", value)

    @_builtins.property
    @pulumi.getter(name="subregionName")
    def subregion_name(self) -> pulumi.Input[_builtins.str]:
        """
        The Subregion in which you want to create the fGPU.
        """
        return pulumi.get(self, "subregion_name")

    @subregion_name.setter
    def subregion_name(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "subregion_name", value)

    @_builtins.property
    @pulumi.getter(name="deleteOnVmDeletion")
    def delete_on_vm_deletion(self) -> Optional[pulumi.Input[_builtins.bool]]:
        """
        If true, the fGPU is deleted when the VM is terminated.
        """
        return pulumi.get(self, "delete_on_vm_deletion")

    @delete_on_vm_deletion.setter
    def delete_on_vm_deletion(self, value: Optional[pulumi.Input[_builtins.bool]]):
        pulumi.set(self, "delete_on_vm_deletion", value)

    @_builtins.property
    @pulumi.getter
    def generation(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The processor generation that the fGPU must be compatible with. If not specified, the oldest possible processor generation is selected (as provided by [ReadFlexibleGpuCatalog](https://docs.outscale.com/api#readflexiblegpucatalog) for the specified model of fGPU).
        """
        return pulumi.get(self, "generation")

    @generation.setter
    def generation(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "generation", value)

    @_builtins.property
    @pulumi.getter
    def timeouts(self) -> Optional[pulumi.Input['FlexibleGpuTimeoutsArgs']]:
        return pulumi.get(self, "timeouts")

    @timeouts.setter
    def timeouts(self, value: Optional[pulumi.Input['FlexibleGpuTimeoutsArgs']]):
        pulumi.set(self, "timeouts", value)


@pulumi.input_type
class _FlexibleGpuState:
    def __init__(__self__, *,
                 delete_on_vm_deletion: Optional[pulumi.Input[_builtins.bool]] = None,
                 flexible_gpu_id: Optional[pulumi.Input[_builtins.str]] = None,
                 generation: Optional[pulumi.Input[_builtins.str]] = None,
                 model_name: Optional[pulumi.Input[_builtins.str]] = None,
                 state: Optional[pulumi.Input[_builtins.str]] = None,
                 subregion_name: Optional[pulumi.Input[_builtins.str]] = None,
                 timeouts: Optional[pulumi.Input['FlexibleGpuTimeoutsArgs']] = None,
                 vm_id: Optional[pulumi.Input[_builtins.str]] = None):
        """
        Input properties used for looking up and filtering FlexibleGpu resources.
        :param pulumi.Input[_builtins.bool] delete_on_vm_deletion: If true, the fGPU is deleted when the VM is terminated.
        :param pulumi.Input[_builtins.str] flexible_gpu_id: The ID of the fGPU.
        :param pulumi.Input[_builtins.str] generation: The processor generation that the fGPU must be compatible with. If not specified, the oldest possible processor generation is selected (as provided by [ReadFlexibleGpuCatalog](https://docs.outscale.com/api#readflexiblegpucatalog) for the specified model of fGPU).
        :param pulumi.Input[_builtins.str] model_name: The model of fGPU you want to allocate. For more information, see [About Flexible GPUs](https://docs.outscale.com/en/userguide/About-Flexible-GPUs.html).
        :param pulumi.Input[_builtins.str] state: The state of the fGPU (`allocated` \\| `attaching` \\| `attached` \\| `detaching`).
        :param pulumi.Input[_builtins.str] subregion_name: The Subregion in which you want to create the fGPU.
        :param pulumi.Input[_builtins.str] vm_id: The ID of the VM the fGPU is attached to, if any.
        """
        if delete_on_vm_deletion is not None:
            pulumi.set(__self__, "delete_on_vm_deletion", delete_on_vm_deletion)
        if flexible_gpu_id is not None:
            pulumi.set(__self__, "flexible_gpu_id", flexible_gpu_id)
        if generation is not None:
            pulumi.set(__self__, "generation", generation)
        if model_name is not None:
            pulumi.set(__self__, "model_name", model_name)
        if state is not None:
            pulumi.set(__self__, "state", state)
        if subregion_name is not None:
            pulumi.set(__self__, "subregion_name", subregion_name)
        if timeouts is not None:
            pulumi.set(__self__, "timeouts", timeouts)
        if vm_id is not None:
            pulumi.set(__self__, "vm_id", vm_id)

    @_builtins.property
    @pulumi.getter(name="deleteOnVmDeletion")
    def delete_on_vm_deletion(self) -> Optional[pulumi.Input[_builtins.bool]]:
        """
        If true, the fGPU is deleted when the VM is terminated.
        """
        return pulumi.get(self, "delete_on_vm_deletion")

    @delete_on_vm_deletion.setter
    def delete_on_vm_deletion(self, value: Optional[pulumi.Input[_builtins.bool]]):
        pulumi.set(self, "delete_on_vm_deletion", value)

    @_builtins.property
    @pulumi.getter(name="flexibleGpuId")
    def flexible_gpu_id(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The ID of the fGPU.
        """
        return pulumi.get(self, "flexible_gpu_id")

    @flexible_gpu_id.setter
    def flexible_gpu_id(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "flexible_gpu_id", value)

    @_builtins.property
    @pulumi.getter
    def generation(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The processor generation that the fGPU must be compatible with. If not specified, the oldest possible processor generation is selected (as provided by [ReadFlexibleGpuCatalog](https://docs.outscale.com/api#readflexiblegpucatalog) for the specified model of fGPU).
        """
        return pulumi.get(self, "generation")

    @generation.setter
    def generation(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "generation", value)

    @_builtins.property
    @pulumi.getter(name="modelName")
    def model_name(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The model of fGPU you want to allocate. For more information, see [About Flexible GPUs](https://docs.outscale.com/en/userguide/About-Flexible-GPUs.html).
        """
        return pulumi.get(self, "model_name")

    @model_name.setter
    def model_name(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "model_name", value)

    @_builtins.property
    @pulumi.getter
    def state(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The state of the fGPU (`allocated` \\| `attaching` \\| `attached` \\| `detaching`).
        """
        return pulumi.get(self, "state")

    @state.setter
    def state(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "state", value)

    @_builtins.property
    @pulumi.getter(name="subregionName")
    def subregion_name(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The Subregion in which you want to create the fGPU.
        """
        return pulumi.get(self, "subregion_name")

    @subregion_name.setter
    def subregion_name(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "subregion_name", value)

    @_builtins.property
    @pulumi.getter
    def timeouts(self) -> Optional[pulumi.Input['FlexibleGpuTimeoutsArgs']]:
        return pulumi.get(self, "timeouts")

    @timeouts.setter
    def timeouts(self, value: Optional[pulumi.Input['FlexibleGpuTimeoutsArgs']]):
        pulumi.set(self, "timeouts", value)

    @_builtins.property
    @pulumi.getter(name="vmId")
    def vm_id(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The ID of the VM the fGPU is attached to, if any.
        """
        return pulumi.get(self, "vm_id")

    @vm_id.setter
    def vm_id(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "vm_id", value)


@pulumi.type_token("outscale:index/flexibleGpu:FlexibleGpu")
class FlexibleGpu(pulumi.CustomResource):
    @overload
    def __init__(__self__,
                 resource_name: str,
                 opts: Optional[pulumi.ResourceOptions] = None,
                 delete_on_vm_deletion: Optional[pulumi.Input[_builtins.bool]] = None,
                 generation: Optional[pulumi.Input[_builtins.str]] = None,
                 model_name: Optional[pulumi.Input[_builtins.str]] = None,
                 subregion_name: Optional[pulumi.Input[_builtins.str]] = None,
                 timeouts: Optional[pulumi.Input[Union['FlexibleGpuTimeoutsArgs', 'FlexibleGpuTimeoutsArgsDict']]] = None,
                 __props__=None):
        """
        Manages a flexible GPU.

        For more information on this resource, see the [User Guide](https://docs.outscale.com/en/userguide/About-Flexible-GPUs.html).\\
        For more information on this resource actions, see the [API documentation](https://docs.outscale.com/api#3ds-outscale-api-flexiblegpu).

        ## Example Usage

        ### Create a flexible GPU

        ```python
        import pulumi
        import pulumi_outscale as outscale

        flexible_gpu01 = outscale.FlexibleGpu("flexible_gpu01",
            model_name=model_name,
            generation="v4",
            subregion_name=f"{region}a",
            delete_on_vm_deletion=True)
        ```

        ## Import

        A flexible GPU can be imported using its ID. For example:

        ```sh
        $ pulumi import outscale:index/flexibleGpu:FlexibleGpu imported_fgpu fgpu-12345678
        ```

        :param str resource_name: The name of the resource.
        :param pulumi.ResourceOptions opts: Options for the resource.
        :param pulumi.Input[_builtins.bool] delete_on_vm_deletion: If true, the fGPU is deleted when the VM is terminated.
        :param pulumi.Input[_builtins.str] generation: The processor generation that the fGPU must be compatible with. If not specified, the oldest possible processor generation is selected (as provided by [ReadFlexibleGpuCatalog](https://docs.outscale.com/api#readflexiblegpucatalog) for the specified model of fGPU).
        :param pulumi.Input[_builtins.str] model_name: The model of fGPU you want to allocate. For more information, see [About Flexible GPUs](https://docs.outscale.com/en/userguide/About-Flexible-GPUs.html).
        :param pulumi.Input[_builtins.str] subregion_name: The Subregion in which you want to create the fGPU.
        """
        ...
    @overload
    def __init__(__self__,
                 resource_name: str,
                 args: FlexibleGpuArgs,
                 opts: Optional[pulumi.ResourceOptions] = None):
        """
        Manages a flexible GPU.

        For more information on this resource, see the [User Guide](https://docs.outscale.com/en/userguide/About-Flexible-GPUs.html).\\
        For more information on this resource actions, see the [API documentation](https://docs.outscale.com/api#3ds-outscale-api-flexiblegpu).

        ## Example Usage

        ### Create a flexible GPU

        ```python
        import pulumi
        import pulumi_outscale as outscale

        flexible_gpu01 = outscale.FlexibleGpu("flexible_gpu01",
            model_name=model_name,
            generation="v4",
            subregion_name=f"{region}a",
            delete_on_vm_deletion=True)
        ```

        ## Import

        A flexible GPU can be imported using its ID. For example:

        ```sh
        $ pulumi import outscale:index/flexibleGpu:FlexibleGpu imported_fgpu fgpu-12345678
        ```

        :param str resource_name: The name of the resource.
        :param FlexibleGpuArgs args: The arguments to use to populate this resource's properties.
        :param pulumi.ResourceOptions opts: Options for the resource.
        """
        ...
    def __init__(__self__, resource_name: str, *args, **kwargs):
        resource_args, opts = _utilities.get_resource_args_opts(FlexibleGpuArgs, pulumi.ResourceOptions, *args, **kwargs)
        if resource_args is not None:
            __self__._internal_init(resource_name, opts, **resource_args.__dict__)
        else:
            __self__._internal_init(resource_name, *args, **kwargs)

    def _internal_init(__self__,
                 resource_name: str,
                 opts: Optional[pulumi.ResourceOptions] = None,
                 delete_on_vm_deletion: Optional[pulumi.Input[_builtins.bool]] = None,
                 generation: Optional[pulumi.Input[_builtins.str]] = None,
                 model_name: Optional[pulumi.Input[_builtins.str]] = None,
                 subregion_name: Optional[pulumi.Input[_builtins.str]] = None,
                 timeouts: Optional[pulumi.Input[Union['FlexibleGpuTimeoutsArgs', 'FlexibleGpuTimeoutsArgsDict']]] = None,
                 __props__=None):
        opts = pulumi.ResourceOptions.merge(_utilities.get_resource_opts_defaults(), opts)
        if not isinstance(opts, pulumi.ResourceOptions):
            raise TypeError('Expected resource options to be a ResourceOptions instance')
        if opts.id is None:
            if __props__ is not None:
                raise TypeError('__props__ is only valid when passed in combination with a valid opts.id to get an existing resource')
            __props__ = FlexibleGpuArgs.__new__(FlexibleGpuArgs)

            __props__.__dict__["delete_on_vm_deletion"] = delete_on_vm_deletion
            __props__.__dict__["generation"] = generation
            if model_name is None and not opts.urn:
                raise TypeError("Missing required property 'model_name'")
            __props__.__dict__["model_name"] = model_name
            if subregion_name is None and not opts.urn:
                raise TypeError("Missing required property 'subregion_name'")
            __props__.__dict__["subregion_name"] = subregion_name
            __props__.__dict__["timeouts"] = timeouts
            __props__.__dict__["flexible_gpu_id"] = None
            __props__.__dict__["state"] = None
            __props__.__dict__["vm_id"] = None
        super(FlexibleGpu, __self__).__init__(
            'outscale:index/flexibleGpu:FlexibleGpu',
            resource_name,
            __props__,
            opts)

    @staticmethod
    def get(resource_name: str,
            id: pulumi.Input[str],
            opts: Optional[pulumi.ResourceOptions] = None,
            delete_on_vm_deletion: Optional[pulumi.Input[_builtins.bool]] = None,
            flexible_gpu_id: Optional[pulumi.Input[_builtins.str]] = None,
            generation: Optional[pulumi.Input[_builtins.str]] = None,
            model_name: Optional[pulumi.Input[_builtins.str]] = None,
            state: Optional[pulumi.Input[_builtins.str]] = None,
            subregion_name: Optional[pulumi.Input[_builtins.str]] = None,
            timeouts: Optional[pulumi.Input[Union['FlexibleGpuTimeoutsArgs', 'FlexibleGpuTimeoutsArgsDict']]] = None,
            vm_id: Optional[pulumi.Input[_builtins.str]] = None) -> 'FlexibleGpu':
        """
        Get an existing FlexibleGpu resource's state with the given name, id, and optional extra
        properties used to qualify the lookup.

        :param str resource_name: The unique name of the resulting resource.
        :param pulumi.Input[str] id: The unique provider ID of the resource to lookup.
        :param pulumi.ResourceOptions opts: Options for the resource.
        :param pulumi.Input[_builtins.bool] delete_on_vm_deletion: If true, the fGPU is deleted when the VM is terminated.
        :param pulumi.Input[_builtins.str] flexible_gpu_id: The ID of the fGPU.
        :param pulumi.Input[_builtins.str] generation: The processor generation that the fGPU must be compatible with. If not specified, the oldest possible processor generation is selected (as provided by [ReadFlexibleGpuCatalog](https://docs.outscale.com/api#readflexiblegpucatalog) for the specified model of fGPU).
        :param pulumi.Input[_builtins.str] model_name: The model of fGPU you want to allocate. For more information, see [About Flexible GPUs](https://docs.outscale.com/en/userguide/About-Flexible-GPUs.html).
        :param pulumi.Input[_builtins.str] state: The state of the fGPU (`allocated` \\| `attaching` \\| `attached` \\| `detaching`).
        :param pulumi.Input[_builtins.str] subregion_name: The Subregion in which you want to create the fGPU.
        :param pulumi.Input[_builtins.str] vm_id: The ID of the VM the fGPU is attached to, if any.
        """
        opts = pulumi.ResourceOptions.merge(opts, pulumi.ResourceOptions(id=id))

        __props__ = _FlexibleGpuState.__new__(_FlexibleGpuState)

        __props__.__dict__["delete_on_vm_deletion"] = delete_on_vm_deletion
        __props__.__dict__["flexible_gpu_id"] = flexible_gpu_id
        __props__.__dict__["generation"] = generation
        __props__.__dict__["model_name"] = model_name
        __props__.__dict__["state"] = state
        __props__.__dict__["subregion_name"] = subregion_name
        __props__.__dict__["timeouts"] = timeouts
        __props__.__dict__["vm_id"] = vm_id
        return FlexibleGpu(resource_name, opts=opts, __props__=__props__)

    @_builtins.property
    @pulumi.getter(name="deleteOnVmDeletion")
    def delete_on_vm_deletion(self) -> pulumi.Output[_builtins.bool]:
        """
        If true, the fGPU is deleted when the VM is terminated.
        """
        return pulumi.get(self, "delete_on_vm_deletion")

    @_builtins.property
    @pulumi.getter(name="flexibleGpuId")
    def flexible_gpu_id(self) -> pulumi.Output[_builtins.str]:
        """
        The ID of the fGPU.
        """
        return pulumi.get(self, "flexible_gpu_id")

    @_builtins.property
    @pulumi.getter
    def generation(self) -> pulumi.Output[_builtins.str]:
        """
        The processor generation that the fGPU must be compatible with. If not specified, the oldest possible processor generation is selected (as provided by [ReadFlexibleGpuCatalog](https://docs.outscale.com/api#readflexiblegpucatalog) for the specified model of fGPU).
        """
        return pulumi.get(self, "generation")

    @_builtins.property
    @pulumi.getter(name="modelName")
    def model_name(self) -> pulumi.Output[_builtins.str]:
        """
        The model of fGPU you want to allocate. For more information, see [About Flexible GPUs](https://docs.outscale.com/en/userguide/About-Flexible-GPUs.html).
        """
        return pulumi.get(self, "model_name")

    @_builtins.property
    @pulumi.getter
    def state(self) -> pulumi.Output[_builtins.str]:
        """
        The state of the fGPU (`allocated` \\| `attaching` \\| `attached` \\| `detaching`).
        """
        return pulumi.get(self, "state")

    @_builtins.property
    @pulumi.getter(name="subregionName")
    def subregion_name(self) -> pulumi.Output[_builtins.str]:
        """
        The Subregion in which you want to create the fGPU.
        """
        return pulumi.get(self, "subregion_name")

    @_builtins.property
    @pulumi.getter
    def timeouts(self) -> pulumi.Output[Optional['outputs.FlexibleGpuTimeouts']]:
        return pulumi.get(self, "timeouts")

    @_builtins.property
    @pulumi.getter(name="vmId")
    def vm_id(self) -> pulumi.Output[_builtins.str]:
        """
        The ID of the VM the fGPU is attached to, if any.
        """
        return pulumi.get(self, "vm_id")

